# Chapter 7. Ensemble Learning and Random Forests

A group of predictions is called ensemble. 

### Objectives 

1. Voting Classifiers
2. Bagging
3. Pasting Ensembles
4. Random Forests
5. Boosting
6. Stacking Ensembles

## Ensemble Methods:

### 1. Voting Classifiers

This allows us to combine multiple different models and make one model out of it which performs better than individual models. But the model selection has to be based on completely different algorithms to make sure that the error that the model commit is different and unique to each model.

### 2. Bagging and Pasting

This approach involves using the same training algorithm for every predictor but train the on different random subsets of the training set. 

When the sampling is performed with replacement this is called bootstrap aggregating: **Bagging**
When sampling is performed without replacement it is called **Pasting**



























